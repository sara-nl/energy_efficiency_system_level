{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import format_node_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('system_analytics_2024/slurm_data/system_states/system_states_1.txt'),\n",
       " PosixPath('system_analytics_2024/slurm_data/system_states/system_states_2.txt'),\n",
       " PosixPath('system_analytics_2024/slurm_data/system_states/system_states_3.txt'),\n",
       " PosixPath('system_analytics_2024/slurm_data/system_states/system_states_4.txt'),\n",
       " PosixPath('system_analytics_2024/slurm_data/system_states/system_states_5.txt'),\n",
       " PosixPath('system_analytics_2024/slurm_data/system_states/system_states_6.txt')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.precision = 4 # show 4 digits precision\n",
    "folder_path_system_states = Path('./system_analytics_2024/slurm_data/system_states')\n",
    "folder_path_slurm_data = Path('./system_analytics_2024/slurm_data')\n",
    "folder_path_saving_results = Path('./results')\n",
    "files = sorted(list(folder_path_system_states.glob(\"*.txt\")))[0:-1]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for file_path in files:\n",
    "def get_date_for_a_day(file_path):\n",
    "    dict_list = []\n",
    "    \n",
    "    with file_path.open(mode='r') as f:\n",
    "        f_text = f.read()\n",
    "    sinfo_day = f_text.split('############################')\n",
    "    for sample_number in range(1, len(sinfo_day)-1):\n",
    "        sinfo_sample = sinfo_day[sample_number].split('\\n')\n",
    "        time = sinfo_sample[1]\n",
    "        for sample_row in range(4, len(sinfo_sample)-1):\n",
    "            sample_row = np.random.randint(4, len(sinfo_sample)-1)\n",
    "            node_number = int(sinfo_sample[sample_row].split()[7])\n",
    "            state = sinfo_sample[sample_row].split()[8]\n",
    "            node_names = sinfo_sample[sample_row].split()[-1]\n",
    "            # print(format_node_names(node_names), node_number, state, time)\n",
    "            d1 = {'node':format_node_names(node_names).split(','), 'time': [time] * node_number, 'state': [state]*node_number}\n",
    "            dict_list.append(d1)\n",
    "    df_list = [pd.DataFrame(d1) for d1 in dict_list]\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df.sort_values(['node', 'time'], inplace=True)\n",
    "    return df\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "with Pool(10) as pool:  # Initialize the pool with 4 processes\n",
    "    parallel_results = pool.map(get_date_for_a_day, files)  # Submit tasks\n",
    "parallel_duration = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>time</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fcn1</td>\n",
       "      <td>2024-11-04 17:03:13</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fcn1</td>\n",
       "      <td>2024-11-04 17:03:43</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fcn1</td>\n",
       "      <td>2024-11-04 17:03:43</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fcn1</td>\n",
       "      <td>2024-11-04 17:04:13</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fcn1</td>\n",
       "      <td>2024-11-04 17:04:13</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node                time  state\n",
       "0  fcn1 2024-11-04 17:03:13  mixed\n",
       "0  fcn1 2024-11-04 17:03:43  mixed\n",
       "0  fcn1 2024-11-04 17:03:43  mixed\n",
       "0  fcn1 2024-11-04 17:04:13  mixed\n",
       "0  fcn1 2024-11-04 17:04:13  mixed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "39630664"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Number of rows we expected to have: 26749440'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.concat(parallel_results, axis=0)\n",
    "df.sort_values(['node', 'time'], inplace=True)\n",
    "s = f\"Number of rows we expected to have: {len(files) * 24 * 60 * 2 * 1548}\"\n",
    "\n",
    "display(df.head(), len(df), s)\n",
    "# why is there duplication? It could be the way I am getting data? or sinfo gives copy of the nodes in any case some of the \n",
    "# node and time are the same. I think sinfo gives the states for some nodes twice in different partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numebr of duplicated rows based on node and time: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>time</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19816906</td>\n",
       "      <td>19816906</td>\n",
       "      <td>19816906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>gcn48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>allocated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>16543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10044035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-07 17:34:31.240479744</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-04 17:03:13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-06 05:24:51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-07 17:34:56</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-09 05:48:34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-10 17:54:36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            node                           time      state\n",
       "count   19816906                       19816906   19816906\n",
       "unique      1548                            NaN         20\n",
       "top        gcn48                            NaN  allocated\n",
       "freq       16543                            NaN   10044035\n",
       "mean         NaN  2024-11-07 17:34:31.240479744        NaN\n",
       "min          NaN            2024-11-04 17:03:13        NaN\n",
       "25%          NaN            2024-11-06 05:24:51        NaN\n",
       "50%          NaN            2024-11-07 17:34:56        NaN\n",
       "75%          NaN            2024-11-09 05:48:34        NaN\n",
       "max          NaN            2024-11-10 17:54:36        NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "state\n",
       "allocated      10044035\n",
       "idle            6366069\n",
       "mixed           2875194\n",
       "reserved         385796\n",
       "drained           76392\n",
       "planned           32005\n",
       "completing        19889\n",
       "draining          10752\n",
       "drained*           3413\n",
       "down*              1291\n",
       "inval              1056\n",
       "unknown             491\n",
       "idle*               294\n",
       "mixed*               92\n",
       "allocated*           54\n",
       "reboot^              33\n",
       "down                 17\n",
       "draining*            15\n",
       "completing*           9\n",
       "mixed-                9\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.drop_duplicates(subset=['node', 'time', 'state'], inplace=True)\n",
    "print(f\"Numebr of duplicated rows based on node and time: {df.duplicated(['node', 'time']).sum()}\")\n",
    "display(df.describe(include='all'), df['state'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "0 days 00:00:30    12347093\n",
       "0 days 00:00:31     2685778\n",
       "0 days 00:01:00     2327416\n",
       "0 days 00:01:01      827238\n",
       "0 days 00:01:30      571694\n",
       "0 days 00:01:31      248289\n",
       "0 days 00:01:02      186819\n",
       "0 days 00:02:00      179731\n",
       "0 days 00:01:32      108477\n",
       "0 days 00:02:01       81318\n",
       "0 days 00:02:30       51775\n",
       "0 days 00:02:31       37463\n",
       "0 days 00:02:02       24225\n",
       "0 days 00:02:03       24119\n",
       "0 days 00:03:00       19388\n",
       "0 days 00:01:33       14074\n",
       "0 days 00:03:01       12076\n",
       "0 days 00:00:32        9871\n",
       "0 days 00:02:34        7503\n",
       "0 days 00:03:30        5555\n",
       "0 days 00:02:33        4897\n",
       "0 days 00:03:31        4325\n",
       "0 days 00:02:32        3899\n",
       "0 days 00:04:01        2725\n",
       "0 days 00:02:04        2654\n",
       "0 days 00:03:02        2443\n",
       "0 days 00:00:33        2362\n",
       "0 days 00:04:00        2012\n",
       "0 days 00:03:04        1694\n",
       "0 days 00:03:32        1604\n",
       "0 days 00:00:35        1482\n",
       "0 days 00:03:03        1391\n",
       "0 days 00:01:03        1085\n",
       "0 days 00:00:56        1074\n",
       "0 days 00:04:02         823\n",
       "0 days 00:04:31         771\n",
       "0 days 00:01:35         745\n",
       "0 days 00:03:05         736\n",
       "0 days 00:03:35         699\n",
       "0 days 00:00:41         670\n",
       "0 days 00:00:34         661\n",
       "0 days 00:05:01         634\n",
       "0 days 00:03:34         524\n",
       "0 days 00:04:06         506\n",
       "0 days 00:05:31         464\n",
       "0 days 00:01:05         457\n",
       "0 days 00:01:41         436\n",
       "0 days 00:01:04         429\n",
       "0 days 00:02:05         406\n",
       "0 days 00:01:11         405\n",
       "0 days 00:03:33         342\n",
       "0 days 00:03:36         311\n",
       "0 days 00:02:26         308\n",
       "0 days 00:01:34         219\n",
       "0 days 00:04:36         195\n",
       "0 days 00:04:30         194\n",
       "0 days 00:01:26         164\n",
       "0 days 00:06:01         104\n",
       "0 days 00:04:03          98\n",
       "0 days 00:04:05          93\n",
       "0 days 00:05:00          85\n",
       "0 days 00:03:06          75\n",
       "0 days 00:05:04          66\n",
       "0 days 00:02:35          44\n",
       "0 days 00:06:08          36\n",
       "0 days 00:02:11          33\n",
       "0 days 00:04:07          31\n",
       "0 days 00:04:34          19\n",
       "0 days 00:05:02           7\n",
       "0 days 00:04:32           3\n",
       "0 days 00:04:35           3\n",
       "0 days 00:01:56           2\n",
       "0 days 00:04:37           2\n",
       "0 days 00:02:41           2\n",
       "0 days 00:05:03           1\n",
       "0 days 00:04:33           1\n",
       "0 days 00:03:41           1\n",
       "0 days 00:06:31           1\n",
       "0 days 00:05:33           1\n",
       "0 days 00:06:03           1\n",
       "0 days 00:02:43           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Are we measuring the data regularly? \n",
    "For the time differences that that multiplication of 30 seconds, it is difficult to say that this delay is because of\n",
    "the absence of the node in the sinfo command or because of the delay in measurement.\n",
    "For the time differences that are not exact multiplication of 30 seconds then it is likely that this error is due to\n",
    "data measuremeant.\n",
    "\n",
    "-- The frequencies that are exact multiplication of 30 seconds also explain why there is a difference between\n",
    "the number of rows that we excpect and what we get. Some nodes are simply absent from the sinfo for some measurement(it could be all of them).\n",
    "\"\"\"\n",
    "\n",
    "df.groupby('node')['time'].diff().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add node_type and removing not workers node\n",
    "df['node_type'] = df['node'].str[0:3]\n",
    "df = df[df['node_type'].isin(['fcn', 'gcn', 'tcn', 'hcn'])].copy()\n",
    "# put the time in an intervale\n",
    "# df['time_5min_rounded'] = (df['time'] - pd.Timedelta('2.5min')).dt.round(freq='5min')\n",
    "df['time_30min_interval'] = (df['time'] - pd.Timedelta('15min')).dt.round(freq='30min')\n",
    "df['time_1hour_interval'] = (df['time'] - pd.Timedelta('30min')).dt.round(freq='h')\n",
    "df['time_3hour_interval'] = (df['time'] - pd.Timedelta('1.5h')).dt.round(freq='3h')\n",
    "df['time_6hour_interval'] = (df['time'] - pd.Timedelta('3h')).dt.round(freq='6h')\n",
    "df['time_day_interval'] = (df['time'] - pd.Timedelta('12h')).dt.round(freq='d')\n",
    "# get a sample\n",
    "display(df.sample(n=10))\n",
    "# save the data\n",
    "# df.to_parquet(folder_path_slurm_data/'sinfo_cleaned.parquet.gzip', compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
